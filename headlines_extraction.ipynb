{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import pytz\n",
    "import threading\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from finvizfinance.quote import finvizfinance\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Supabase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection():\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            dbname=os.getenv('DB_NAME'),\n",
    "            user=os.getenv('DB_USER'),\n",
    "            password=os.getenv('DB_PASSWORD'),\n",
    "            host=os.getenv('DB_HOST'),\n",
    "            options='-c statement_timeout=1020000'\n",
    "        )\n",
    "\n",
    "    except psycopg2.OperationalError as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        print('Connected Established!')\n",
    "        return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = get_connection()\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching headlines from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT Ticker FROM Stocks\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "tickers = cursor.fetchall()\n",
    "tickers = [ticker[0] for ticker in tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dfs = {}\n",
    "\n",
    "def get_news(ticker):\n",
    "    print(f'Fetching headlines for {ticker}...')\n",
    "    stock = finvizfinance(ticker)\n",
    "    news_df = stock.ticker_news()\n",
    "    return news_df \n",
    "\n",
    "def fetch_headlines(ticker):\n",
    "    try:\n",
    "        news_dfs[ticker] = get_news(ticker)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching headlines for {ticker}: {e}\")\n",
    "        fetch_headlines(ticker)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        executor.submit(fetch_headlines, ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting headlines in categories based on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now(pytz.timezone('US/Eastern'))\n",
    "et_now = current_time.replace(second=0, microsecond=0).replace(tzinfo=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ET(dt):\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    return dt.astimezone(eastern)\n",
    "\n",
    "def extract_headlines_within_one_day(df, current_time):\n",
    "    one_day_ago = current_time - pd.Timedelta(days=1)\n",
    "    return df[df['Date'] >= one_day_ago]\n",
    "\n",
    "def extract_headlines_within_one_week(df, current_time):\n",
    "    one_week_ago = current_time - pd.Timedelta(weeks=1)\n",
    "    return df[df['Date'] >= one_week_ago]\n",
    "\n",
    "def extract_headlines_within_one_month(df, current_time):\n",
    "    one_month_ago = current_time - pd.Timedelta(days=30)\n",
    "    return df[df['Date'] >= one_month_ago]\n",
    "\n",
    "def extract_headlines_within_timeframes(dictionary_of_dataframes):\n",
    "    current_time_ET = convert_to_ET(datetime.datetime.now())\n",
    "    current_time_ET = current_time_ET.replace(second=0, microsecond=0).replace(tzinfo=None)\n",
    "\n",
    "    headlines_within_timeframes = {}\n",
    "\n",
    "    for stock, df in dictionary_of_dataframes.items():\n",
    "        daily_headlines = extract_headlines_within_one_day(df, current_time_ET)\n",
    "        weekly_headlines = extract_headlines_within_one_week(df, current_time_ET)\n",
    "        monthly_headlines = extract_headlines_within_one_month(df, current_time_ET)\n",
    "        \n",
    "        headlines_within_timeframes[stock] = {\n",
    "            'Daily': daily_headlines,\n",
    "            'Weekly': weekly_headlines,\n",
    "            'Monthly': monthly_headlines\n",
    "        }\n",
    "    \n",
    "    return headlines_within_timeframes\n",
    "\n",
    "df = extract_headlines_within_timeframes(news_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for database insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for ticker, period_data in df.items():\n",
    "    for period, dataframe in period_data.items():\n",
    "\n",
    "        if period == 'Daily':\n",
    "            dataframe['is_daily'] = True\n",
    "            dataframe['is_weekly'] = True\n",
    "            dataframe['is_monthly'] = True\n",
    "\n",
    "        elif period == 'Weekly':\n",
    "            dataframe['is_daily'] = False\n",
    "            dataframe['is_weekly'] = True\n",
    "            dataframe['is_monthly'] = True\n",
    "\n",
    "        elif period == 'Monthly':\n",
    "            dataframe['is_daily'] = False\n",
    "            dataframe['is_weekly'] = False\n",
    "            dataframe['is_monthly'] = True\n",
    "\n",
    "        desired_columns_order = ['Date', 'Title', 'Link','is_daily', 'is_weekly', 'is_monthly']\n",
    "        dataframe = dataframe[desired_columns_order]\n",
    "\n",
    "        dfs.append(dataframe.assign(Ticker=ticker, Period=period))\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "filtered_df = merged_df.drop_duplicates(subset=['Ticker', 'Title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.loc[:, 'Date'] = filtered_df['Date'].astype(str)\n",
    "\n",
    "filtered_df.loc[:, 'is_daily'] = filtered_df['is_daily'].astype(str).str.lower()\n",
    "filtered_df.loc[:, 'is_weekly'] = filtered_df['is_weekly'].astype(str).str.lower()\n",
    "filtered_df.loc[:, 'is_monthly'] = filtered_df['is_monthly'].astype(str).str.lower()\n",
    "\n",
    "values = [tuple(row) for row in filtered_df[['Date', 'Ticker', 'Title', 'is_daily', 'is_weekly', 'is_monthly']].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertion in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "def insert_rows(values):\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        cur.execute('DELETE FROM headlines')\n",
    "        conn.commit()\n",
    "\n",
    "        query = '''\n",
    "        INSERT INTO headlines (publication_timestamp, ticker, headline, is_daily, is_weekly, is_monthly)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        '''\n",
    "\n",
    "        for value in values:\n",
    "            cur.execute(query, value)\n",
    "            print(value)\n",
    "\n",
    "        conn.commit() \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        if conn:\n",
    "            conn.rollback()  \n",
    "\n",
    "    finally:\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "num_threads = 8\n",
    "chunk_size = len(values) // num_threads + 1\n",
    "value_chunks = [values[i:i+chunk_size] for i in range(0, len(values), chunk_size)]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    futures = [executor.submit(insert_rows, chunk) for chunk in value_chunks]\n",
    "    for future in futures:\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
